# 9.6 검색엔진

웹 로봇을 가장 광범위하게 사용하는 것은 인터넷 검색엔진이다. 인터넷 검색엔진은 사용자가 전 세계의 어떤 주제에 대한 문서라도 찾을 수 있게 해 준다.

웹 크롤러들은 마치 먹이를 주듯 검색엔진에게 웹에 존재하는 문서들을 가져다 주어서, 검색엔진이 어떤 문서에 어떤 단어들이 존재하는지에 대한 색인을 생성할 수 있게 한다.

<br />

### 9.6.1 넓게 생각하라

웹이 아직 초창기였을 때, 검색엔진들은 사용자들이 웹상에서 문서의 위치를 알아내는 것을 돕는 상대적으로 단순한 데이터베이스였다. 웹에서 수십억 개의 페이지들이 접근 가능한 오늘날, 인터넷 사용자들의 정보 찾기를 도와주는 검색엔진들은 필수가 되었다. 그리고 급격히 성장하는 웹을 다루기 위해 진화하면서 꽤나 복잡해졌다.

수백만 명의 사용자들이 수십억 개의 웹페이지에서 원하는 정보를 찾는 상황에서, 수백만 명의 사용자들이 생성하는 질의로 인한 부하를 다루기 위해 복잡한 질의 엔진이 필요한 것과 마찬가지로, 검색엔진은 수십억 개의 웹페이지들을 검색하기 위해 복잡한 크롤러를 사용해야 한다.

<br />
<br />

### 9.6.2 현대적인 검색엔진의 아키텍쳐

오늘날 검색엔진들은 그들이 갖고 있는 전 세계의 웹페이지들에 대해 '풀 텍스트 색인(full-text indexes)'이라고 하는 복잡한 로컬 데이터베이스를 생성한다.

검색엔진 크롤러들은 웹페이지들을 수집하여 집으로 가져와서, 이 풀 텍스트 색인에 추가한다. 동시에, 검색엔진 사용자들은 핫봇이나 구글과 같은 웹 검색 게이트웨이를 통해 풀 텍스트 색인에 대한 질의를 보낸다.

<img width="650" alt="크롤러와 질의 게이트웨이의 협업을 포함한 상용 검색엔진" src="https://user-images.githubusercontent.com/75570915/215272187-4ec2a6d2-0993-40fd-9298-64025c0a266b.png">

<br />
<br />

### 9.6.3 풀 텍스트 색인

풀 텍스트 색인은 단어 하나를 입력받아 그 단어를 포함하고 있는 문서를 즉각 알려줄 수 있는 데이터베이스다.

<img width="650" alt="세 문서와 풀 텍스트 색인" src="https://user-images.githubusercontent.com/75570915/215272193-7cc2ae71-26f9-4e96-8996-70b7cdc850a6.png">

- 단어 'a'는 문서 A와 B에 들어있다.
- 단어 'best'는 문서 A와 C에 들어있다.
- 단어 'drill'은 문서 A와 B에 들어있다.
- 단어 'the'는 새 문서 A,B,C 모두에 들어있다.

<br />
<br />

### 9.6.4 질의 보내기

사용자가 질의를 웹 검색엔진 게이트웨이로 보내는 방법은, HTML 폼을 사용자가 채워 넣고 브라우저가 그 폼을 HTTP GET이나 POST 요청을 이용해서 게이트웨이로 보내는 식이다.

<br />
<br />

### 9.6.5 검색 결과를 정렬하고 보여주기

질의의 결과를 확인하기 위해 검색엔진이 색인을 한번 사용했다면, 게이트웨이 애플리케이션은 그 결과를 이용해 최종 사용자를 위한 결과 페이지를 즉석에서 만들어낸다. 많은 웹페이지가 주어진 단어를 포함할 수 있기 때문에, 검색엔진은 결과에 순위를 매기기 위해 똑똑한 알고리즘을 사용한다.

어떤 주어진 페이지를 가리키는 링크들이 얼마나 많은지 세는 것은 그 문서의 인기도를 관별하는데 도움이 된다. 그리고 이 정보는 결과를 보여줄 때 정렬 순서에 대한 가중치로 사용될 수 있다. 검색엔진에 의해 사용되는 알고리즘, 크롤링에 대한 팁, 그 외 각종 기교는 검색엔진의 가장 엄격히 감추어진 비밀들이다.

<br />
<br />

### 9.6.6 스푸핑

사용자들은 자신이 찾는 내용이 검색 결과의 최상위 몇 줄에서 보이지 않는다면 대개 불만족스러워 하므로, 웹 사이트를 찾을 때 검색 결과의 순서는 중요하다. 웹 마스터에게는 자신이 만든 사이트가 그 자신을 가장 잘 설명하는 단어로 검색한 결과의 상단에 노출되도록 만들 동기가 충분하다.

많은 웹 마스터가 수많은 키워드들을 나열한 가짜 페이지를 만들거나, 더 나아가서는 검색엔진의 관련도 알고리즘을 더 잘 속일 수 있는, 특정 단어에 대한 가짜 페이지를 생성하는 게이트웨이 애플리케이션을 만들어 사용한다. 결국 검색엔진과 로봇 구현자들은 이러한 속임수를 더 잘 잡아내기 위해 끊임없이 그들의 관련도 알고리즘을 수정해야하만 한다.
