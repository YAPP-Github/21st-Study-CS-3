# 9.5 로봇 에티켓

이 장에서는 [로봇 제작자들을 위한 가이드라인](https://www.robotstxt.org/guidelines.html) 콘텐츠와 정신을 존중하는 것에 무게를 두면서, 로봇 설계자들과 운영자들을 위해 현대적으로 고쳐 쓴 것이다. 이 가이드라인의 대부분은 월드 와이드 웹 로봇들을 대상으로 한 것이지만, 작은 규모의 크롤러에도 역시 적용 가능하다.

<br />
<br />

## 가이드라인

### (1) 신원 식별

#### 로봇의 신원을 밝혀라

HTTP User-Agent 필드를 사용해서 웹 서버에게 로봇의 이름을 말하라. 이는 관리자들이 로봇이 무엇을 하는지 이해하는데 도움을 줄 것이다.

<br />

#### 기계의 신원을 밝히라

로봇이 DNS 엔트리를 가진 기계에서 실행된다는 것을 확실히 해서, 웹 사이트가 로봇의 IP 주소를 호스트 명을 통해 역방향 DNS를 할 수 있도록 하라. 이것은 관리자들이 로봇에 대해 책임이 있는 조직이 어디인지 식별할 수 있게 해준다.

<br />

#### 연락처를 밝혀라

HTTP 폼 필드를 사용해서 연락할 수 있는 이베일 주소를 제공하라.

<br />
<br />

### (2) 동작

#### 긴장하라

로봇을 운영하기 시작하면 문의와 항의가 들어오게 될 것이다. 로봇 운영자는 반드시 자신의 로봇이 올바르게 행동하는지 조심스럽게 지켜보아야 한다.

<br />

#### 대비하라

로봇 운영자는 자신이 속한 조직에 그 사실을 알려둘 필요가 있다. 조직은 네트워크 대역폭의 소비를 감시하길 원할 것이며 어떠한 문의에도 응할 주닙가 되어있을 것이다.

<br />

#### 감시와 로그

로봇은 진행상황을 추적하고, 로봇 함정을 식별하고, 모든 것이 정상적으로 동작하는지 기본적인 검사가 가능하도록 진단과 로깅 기능을 풍부하게 갖추어야 한다. 오작동하는 웹 크롤러를 디버깅할 때 뿐 아니라 근거 없는 불평에 대한 방어를 위해서도 중요하다.

<br />

#### 배우고 조정하라

크롤링을 할 때마다 새로운 것을 배우게 될 것이다. 매번 로봇을 조정하고 개선하여 흔한 함정에 빠지는 것을 피하라.

<br />
<br />

### (3) 스스로를 제한하라

#### URL을 필터링하라

만악 URL이 이해할 수 없거나 관심 없는 데이터를 참조하고 있는 것 같다면 그냥 무시하는 것이 좋다. 예를 들어, '.gz', '.tar'로 끝나는 URL은 압축파일이나 아카이브일 것이다. '.exe'는 실행 프로그램, '.gif', '.jpg'는 이미지일 것이다.

<br />

#### 동적 URL을 필터링하라

보통 로봇들은 동적인 게이트웨이로부터의 콘텐츠를 크롤링할 필요가 없다. 만약 URL이 'cgi'나 '?'를 포함하고 있다면, 로봇은 그 URL을 크롤링하지 않는 편이 나을 수도 있다.

<br />

#### Accept 관련 헤더로 필터링

로봇은 HTTP Accept 관련 헤더들을 이용해서 서버에게 어떤 콘텐츠를 이해할 수 있는지 말해주어야 한다.

<br />

#### robots.txt에 따르라

로봇은 방문한 웹 사이트에서 robots.txt의 제어에 따라야 한다.

<br />

#### 스스로를 억제하라

로봇은 웹 사이트에 접근할 때마다 몇 번 접근했는지 세고, 이 정보를 이용해서 특정 사이트에 너무 자주 방문하지 않도록 해야 한다. 로봇이 끊임없이 쳐들어와서 다른 모든 트래픽을 막아버리면, 관리자들은 분노하게 될 것이다.

<br />
<br />

### (4) 루프와 중복을 견뎌내기, 그리고 그 외의 문제들

#### 모든 응답 코드 다루기

웹 로봇 운영자는 반드시 모든 리다이렉트와 에러를 포함한 모든 HTTP 상태 코드를 다룰 수 있도록 준비되어 있어야 한다. 또한 이 코드들의 로그를 남기고 모니터링 해야 한다.

<br />

#### URL 정규화하기

모든 URL을 표준화된 형식으로 정규화함으로써 같은 자원을 가리키는 중복된 URL들을 제거하고자 노력하라.

<br />

#### 적극적으로 순환 피하기

순환을 감지하고 피하기 위해 많은 노력을 하라. 크롤링 운영 과정을 피드백 루프처럼 만들어라. 반드시 다음번 크롤링에 반영되어서 크롤러가 점점 더 나아질 수 있도록 해야 한다.

<br />
<br />

### (5) 확장성

#### 공간 이해하기

애플리케이션이 로봇 작업 하나를 마치는데 얼마나 많은 메모리를 요구하게 될 것인지 미리 계산하라.

<br />

#### 대역폭 이해하기

네트워크 대역폭의 실제 사용량을 측정하라. 네트워크 사용량을 모니터링 함으로써, 로봇을 더 잘 최적화할 수 있는 가능성을 찾을 수도 있을 것이고, 그렇게 되면 TCP 커넥션을 더 효율적으로 사용하여 네트워크 대역폭 면에서 이득을 가져올 수도 있을 것이다.

<br />

### (6) 신뢰성

#### 철저하게 테스트하라 

로봇을 세상에 풀어놓기 전에 내부에서 철저하게 테스트하라. 결과를 많이 수집하고 성능과 메모리 사용량을 분석해서 문제가 커짐에 따라 요구량이 얼마나 늘어나게 될지 추정하라.

<br />

#### 체크포인트 

어떤 진지한 로봇은 실패한 위치에서 다시 시작하기 위해 진행상황의 스냅샷을 저장하고 싶어 할 것이다. 소프트웨어 버그를 발견할 수도 있고 하드웨어가 실패할 수도 있다. 대규모 로봇은 이런 일이 있을 때마다 처음부터 다시 시작할 수 없다. 체크포인트/재시작 기능을 처음부터 설계하라.

<br />

### (7) 소통

#### 이해하라 

로봇 차단 규칙 표준에 대해 설명하고, 항의를 받은 URL을 즉각 크롤러에서 제거하고 블랙리스트에 추가하라.

