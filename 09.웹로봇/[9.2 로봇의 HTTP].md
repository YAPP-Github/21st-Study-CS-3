## 9.2 로봇의 HTTP
- 로봇들은 다른 클라이언트 프로그램과 다르지 않음. 웹로봇도 HTTP요청 헤더를 사용

### 9.2.1 요청 헤더 식별하기
- 잘못된 크롤러의 소유자를 찾아낼 때와 서버에게 로봇이 어떤 종류의 콘텐츠를 다룰 수 있는지에 대한 약간의 정보를 주기 위함 -> 신원 식별 헤더를 전송
  - User-Agent :서버에게 요청을 만든 로봇의 이름
  - From : 로봇은 사용자/관리자의 이메일 주소
  - Accept : 서버에게 어떤 미디어 타입을 보내도 되는지
  - Referer : 현재의 요청 URL을 포함한 문서의 URL을 제공한다.

### 9.2.2 가상 호스팅
요청에 Host 헤더를 포함하지 않으면 로봇이 어떤 URL에 대해 잘못된 콘텐츠를 찾게 만드므로 `HTTP/1.1` 에서 Host 헤더를 요구

- 두 개의 사이트(www.joes.hardware.com, www.foo.com)를 운영하는 서버에 `host`헤더를 포함하지 않고 요청을 보냈을 때, 서버가 기본적으로 www.joes.hardware.com 를 제공하도록 설정되어 있다면 www.foo.com페이지에 대한 요청은 www.joes.hardware.com에 대한 콘텐츠를 얻게 되고, 크롤러는 이를 구분할 수 없다.

![](https://velog.velcdn.com/images/yoose1002/post/f495248e-1be2-4299-b1e2-be41e672d390/image.png)
### 9.2.3 조건부 요청
- 로봇이 엄청난 양의 요청을 시도하는 경우, 요청을 모두 수행하기 보다는 **변경된 콘텐츠**만 가져오는 것!
- **시간**이나 **엔티티 태그**를 비교하여서, 로봇이 받아간 마지막 버전 이후에 업데이트된 것이 있는지 알아보는 조건부 HTTP 요청을 구현. 
   - 8장 게이트웨이 와 비슷하죠?
### 9.2.4 응답 다루기
- 웹 탐색 및 서버와의 상호작용을 더 잘 수행하려는 로봇들은 여러 종류의 HTTP 응답을 다룰 줄 알 필요가 있음.

#### 상태 코드

- 로봇은 일반적인 상태 코드나 예상할 수 있는 상태 코드는 다룰 수 있어야 함. 
- 200, 404 같은 건 상태코드는 무조건 제어
- 이해할 수 없는 코드라고 하더라도, 해당 코드가 속한 분류 2xx, 3xx, 4xx, 5xx의 분류에 따라 처리할 수 있어야 함.

### 엔터티
- http-equiv 태그 : 리소스에 대해 콘텐츠 저자가 포함시킨 메타 HTML 태그
- http-equiv 태그 자체는 콘텐츠 저자 측에서, 콘텐츠를 다루는 서버가 제공할 수도 있는 헤더를 덮어쓰기 위한 수단임.
```js
<meta http-equiv="Refresh" content="1; URL=index.html">
```
=> 로봇이 HTML 문서를 따라가는 과정에서 이와 같은 메타 태그를 발견하게 되면 수신자가 문서를 마치 그 문서의 HTTP 응답 값이 `"1; URL=index.html"` 인 Refresh HTTP 헤더를 포함하고 있는 것처럼 다루게 함.

### 9.2.5 User-Agent 타기팅

- 웹 관리자는 로봇들로부터의 요청을 예상
- 웹 사이트는 브라우저의 종류를 감지하여 그에 맞게 콘텐츠를 최적화
- 웹 로봇이 사이트에 방문했다가 콘텐츠를 얻을 수 없는 일이 없도록 대비할 수 있는 유연한 페이지 개발